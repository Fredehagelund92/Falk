# falk Configuration
# Single source for agent behavior, extensions, and access control.
# Metrics and dimensions are defined in semantic_models.yaml (Boring Semantic Layer)

version: 1

# Project Metadata
project:
  name: my-falk-project
  description: AI-powered data agent for metric queries

# Database Connection (inline — no separate profiles file)
connection:
  type: duckdb
  database: data/warehouse.duckdb

# BigQuery: type: bigquery, project_id: your-project, dataset_id: analytics
# Snowflake: type: snowflake, user: ..., password: ${SNOWFLAKE_PASSWORD}, account: ..., database: ..., schema: ...

# Agent Configuration (analyst-facing)
agent:
  # LLM Provider
  provider: openai  # openai, anthropic, gemini, mistral
  model: gpt-5-mini  # or gpt-5-nano, claude-sonnet-4, gemini-pro, etc.
  
  # Business Context - This is your company's data story
  context: |
    We're a SaaS company selling analytics software.
    The funnel is: trials -> signups -> paid customers -> revenue.
    "Customer" = organization using our software.
  
  # Example Questions - Help users know what to ask
  examples:
    - "What's our revenue by region this month?"
    - "Show me top 5 customers by trials"
    - "Compare this week to last week"
    - "Daily breakdown of conversions"
  
  # Rules - Important constraints the agent should follow
  rules:
    - "Revenue data has a 24-hour processing delay"
    - "Always mention the date range when showing results"
    - "Use 'MRR' not 'monthly recurring revenue'"
  
  # Global gotchas (optional) - caveats not tied to one metric/dimension
  gotchas:
    - "Data from the current day may be incomplete until the daily pipeline finishes"
  
  # Welcome Message
  welcome: |
    Hi! I can help you explore your data.
    Try asking:
    - "What's our revenue by region?"
    - "Show me top customers"

  # Optional custom prompt sections (advanced)
  custom_sections:
    - title: Reporting Conventions
      content: |
        - Use USD unless the user asks for another currency.
        - Round percentages to one decimal place.
  
  # Knowledge files loaded into the system prompt
  knowledge:
    enabled: true
    business_path: knowledge/business.md
    gotchas_path: knowledge/gotchas.md
    load_mode: startup  # startup (phase 1), on_demand reserved for future

# Observability (optional - auto-enabled if env vars are set)
# Set LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY, LANGFUSE_HOST in .env to enable
observability:
  langfuse_sync: true  # Flush after each trace (ensures data sent before process exit)

# Paths (relative to project root)
paths:
  semantic_models: semantic_models.yaml  # BSL file

# Session State Storage (for multi-user deployments)
session:
  store: memory  # "memory" (single process) or "redis" (multi-worker)
  url: redis://localhost:6379  # Redis URL (only used if store=redis)
  ttl: 3600  # Session TTL in seconds (1 hour)
  maxsize: 500  # Max sessions for memory store

# Advanced Settings (technical — hidden from analyst config)
advanced:
  auto_run: false  # Reserved for future use
  max_tokens: 4096
  temperature: 0.1
  max_rows_per_query: 10000
  query_timeout_seconds: 30   # warehouse/tool execution (e.g. query_metric)
  model_timeout_seconds: 60   # LLM request (single turn)
  slack_run_timeout_seconds: 120  # Whole Slack run (model + tools)
  tool_calls_limit: 8   # Max tool calls per run (prevent tool loops)
  request_limit: 6      # Max LLM requests per run
  max_retries: 3
  retry_delay_seconds: 1
  log_level: INFO  # DEBUG, INFO, WARNING, ERROR

