{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"falk","text":"<p>Governed AI access to your data warehouse, powered by semantic layers.</p> <p>Define metrics once in YAML. Query them naturally through Slack, CLI chat, or MCP. Same numbers everywhere. No SQL generation. No prompt engineering.</p>"},{"location":"#the-idea","title":"The idea","text":"<p>Most AI data agents let models write raw SQL over your warehouse. That's powerful for exploration \u2014 but dangerous for production, where \"revenue\" needs to mean the same thing every time.</p> <p>falk puts your semantic layer in charge. The agent reads governed metric definitions instead of guessing from table schemas. Every query goes through the same calculations your BI tools use.</p> <pre><code># semantic_models.yaml \u2014 define once, query everywhere\nsales_metrics:\n  measures:\n    revenue:\n      expr: _.amount.sum()\n      description: \"Total revenue (completed orders only)\"\n      synonyms: [\"sales\", \"income\"]\n      related_metrics: [orders, average_order_value]\n</code></pre>"},{"location":"#what-you-get","title":"What you get","text":"<ul> <li>Governed access \u2014 only approved metrics and dimensions, not raw tables</li> <li>MCP server \u2014 standard protocol for AI tools (Cursor, Claude Desktop, any MCP client)</li> <li>Consistent numbers \u2014 same calculation as your BI layer</li> <li>Business context \u2014 synonyms, gotchas, and rules built into the schema</li> <li>Automatic root cause \u2014 ask \"why did revenue increase?\" and get a real answer</li> <li>Multi-interface \u2014 MCP server, Slack, CLI chat \u2014 same data everywhere</li> </ul>"},{"location":"#quick-start","title":"Quick start","text":"<pre><code>git clone https://github.com/Fredehagelund92/Falk.git\ncd falk &amp;&amp; uv venv &amp;&amp; uv sync\n\nfalk init my-project\ncd my-project\n\n# Configure environment\ncp .env.example .env  # edit: POSTGRES_URL and OPENAI_API_KEY\n\n# Validate configuration\nfalk validate --fast\n\n# Start MCP server (connect from Cursor, Claude Desktop)\nfalk mcp\n\n# OR start local web chat (Pydantic AI built-in UI)\nfalk chat   # -&gt; http://127.0.0.1:8000\n\n# OR start Slack bot\nfalk slack\n</code></pre>"},{"location":"#learn-more","title":"Learn more","text":"Topic Description Why falk? The philosophy behind semantic-layer AI Quick Start Full setup walkthrough Semantic Models Define your metrics CLI Reference All commands"},{"location":"#deployment-note-010","title":"Deployment note (0.1.0)","text":"<ul> <li>Alpha / vibe coded \u2014 not battle-tested for production yet. Use at your own risk.</li> <li>Recommended model: one company/workspace per deployment (single-tenant).</li> <li>In production (<code>FALK_ENV=production</code>), configure <code>access_policies</code> to avoid open access.</li> <li>Session storage uses PostgreSQL by default (<code>session.store: postgres</code>). Set <code>POSTGRES_URL</code> in <code>.env</code>.</li> <li>Session config precedence is env vars &gt; <code>falk_project.yaml</code> &gt; defaults.</li> <li>Chart generation uses ephemeral aggregate state; rerun the query if a restart/worker switch drops chart context.</li> <li>Slack exports default to DM-only delivery; optionally allow specific channels via <code>slack.export_channel_allowlist</code>.</li> </ul>"},{"location":"#inspiration-credits","title":"Inspiration &amp; Credits","text":"<p>falk was inspired by excellent work in the data agent space:</p> <ul> <li>OpenAI's in-house data agent \u2014 Grounded metric querying and data agents</li> <li>nao \u2014 Context engineering patterns and agent reliability testing</li> <li>dash \u2014 Self-learning from feedback and six layers of context</li> </ul> <p>We're grateful to these projects for showing what's possible with well-designed data agents.</p>"},{"location":"cli-reference/","title":"CLI Reference","text":"<p>Run <code>falk --help</code> or <code>falk &lt;command&gt; --help</code> for the latest options.</p>"},{"location":"cli-reference/#falk-init","title":"<code>falk init</code>","text":"<p>Scaffold a new falk project.</p> <pre><code>falk init my-project\nfalk init .                    # scaffold into current directory\nfalk init analytics --warehouse snowflake --no-sample-data\n</code></pre> <p>Creates: <code>RULES.md</code>, <code>knowledge/</code>, <code>semantic_models.yaml</code>, <code>falk_project.yaml</code>, <code>.env.example</code>, and sample data (DuckDB). Use <code>falk init .</code> to add scaffold files to the current directory instead of creating a subdirectory.</p>"},{"location":"cli-reference/#falk-config","title":"<code>falk config</code>","text":"<p>Show current configuration.</p> <pre><code>falk config\nfalk config --all\n</code></pre>"},{"location":"cli-reference/#falk-validate","title":"<code>falk validate</code>","text":"<p>Validate project configuration, semantic models, and optional runtime checks.</p> <pre><code>falk validate                 # Full validation (including connection + agent init)\nfalk validate --fast          # Config/semantic/knowledge checks only\nfalk validate --no-connection # Skip warehouse connection test\nfalk validate --no-agent      # Skip agent initialization test\nfalk validate --verbose       # Show details for each check\n</code></pre> <p>Validation phases include: 1. Configuration validation (falk_project.yaml) 2. Semantic layer validation (BSL models) 3. Knowledge file validation 4. Warehouse connection test (optional) 5. Agent initialization test (optional)</p>"},{"location":"cli-reference/#falk-test","title":"<code>falk test</code>","text":"<p>Run eval cases from <code>evals/</code> to verify behavior.</p> <pre><code>falk test                      # Run all eval files (*.yaml)\nfalk test --pattern \"*.yaml\"   # Choose eval file glob\nfalk test --tags access,gotchas\nfalk test --verbose\n</code></pre>"},{"location":"cli-reference/#falk-mcp","title":"<code>falk mcp</code>","text":"<p>Start the MCP server.</p> <pre><code>falk mcp\n</code></pre> <p>Exposes tools via Model Context Protocol for use with: - Cursor - Claude Desktop - Any MCP-compatible client</p> <p>See MCP Guide for setup instructions.</p>"},{"location":"cli-reference/#falk-chat","title":"<code>falk chat</code>","text":"<p>Start local web chat with the data agent (Pydantic AI built-in web UI).</p> <pre><code>falk chat\n</code></pre> <p>Behavior: - Starts the local web server at <code>http://127.0.0.1:8000</code>. - Uses Pydantic AI's built-in web UI (no separate frontend required).</p>"},{"location":"cli-reference/#falk-access-test","title":"<code>falk access-test</code>","text":"<p>Run a question as a specific user identity to test access policies.</p> <pre><code>falk access-test --list-users\nfalk access-test --user analyst@company.com\nfalk access-test --user viewer@company.com --question \"Describe the orders metric\"\n</code></pre>"},{"location":"cli-reference/#falk-slack","title":"<code>falk slack</code>","text":"<p>Start the Slack bot.</p> <pre><code>falk slack\n</code></pre> <p>Requires <code>SLACK_BOT_TOKEN</code> and <code>SLACK_APP_TOKEN</code> in <code>.env</code>.</p>"},{"location":"cli-reference/#troubleshooting","title":"Troubleshooting","text":"Issue Solution <code>falk chat</code> \u2014 DataAgent init fails Run <code>falk validate</code> to check configuration. Ensure <code>.env</code> has required API keys (e.g. <code>OPENAI_API_KEY</code>). Warehouse connection error Check <code>falk_project.yaml</code> and <code>profiles.yml</code> for correct database connection."},{"location":"cli/","title":"CLI Overview","text":"<p>The <code>falk</code> CLI manages projects, runs tests, and starts servers.</p> <p>For data queries and agent interactions, use: - MCP server (<code>falk mcp</code>) - Connect from Cursor, Claude Desktop, or any MCP client - Web UI (<code>falk chat</code>) - Interactive web interface - Slack bot (<code>falk slack</code>) - Team collaboration</p>"},{"location":"cli/#getting-started","title":"Getting started","text":"<pre><code># After installing\npip install falk\n\n# Or from source\ngit clone https://github.com/Fredehagelund92/Falk.git\ncd Falk\nuv sync\n</code></pre>"},{"location":"cli/#commands","title":"Commands","text":""},{"location":"cli/#project-management","title":"Project Management","text":"Command What it does <code>falk init</code> Create a new project with sample data <code>falk validate</code> Validate configuration, models, and optional runtime checks <code>falk test</code> Run eval cases from <code>evals/</code> <code>falk config</code> Show current project configuration"},{"location":"cli/#servers","title":"Servers","text":"Command What it does <code>falk mcp</code> Start MCP server (for Cursor, Claude Desktop) <code>falk chat</code> Start web UI (default: port 8000) <code>falk slack</code> Start Slack bot"},{"location":"cli/#examples","title":"Examples","text":"<pre><code># Create a new project\nfalk init my-project\ncd my-project\n\n# Validate configuration\nfalk validate --fast\n\n# Start MCP server (connect from Cursor)\nfalk mcp\n\n# Or start web UI for interactive queries\nfalk chat\n\n# Or start Slack bot for team collaboration\nfalk slack\n</code></pre> <p>For full details on every command and option, see the CLI Reference.</p>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#setup","title":"Setup","text":"<pre><code>git clone https://github.com/Fredehagelund92/Falk.git\ncd Falk\nuv venv\nuv sync --extra dev\n</code></pre>"},{"location":"contributing/#project-structure","title":"Project structure","text":"<pre><code>src/falk/                         \u2190 The library (pip-installable)\n\u251c\u2500\u2500 agent.py                      # DataAgent core (BSL models + all data methods)\n\u251c\u2500\u2500 llm/                          # Pydantic AI Agent + tool definitions\n\u251c\u2500\u2500 prompt.py                     # System prompt construction\n\u251c\u2500\u2500 settings.py                   # Configuration loading\n\u251c\u2500\u2500 cli.py                        # Typer CLI\n\u251c\u2500\u2500 validation.py                 # Project validation and testing\n\u251c\u2500\u2500 observability/                # Tracing and feedback\n\u2502   \u2514\u2500\u2500 feedback.py               # Feedback recording\n\u251c\u2500\u2500 backends/                     # Pluggable backends\n\u2502   \u251c\u2500\u2500 memory/                   # Memory (hindsight)\n\u2502   \u251c\u2500\u2500 observability/            # Logfire\n\u2502   \u2514\u2500\u2500 session/                  # Postgres + memory session stores\n\u251c\u2500\u2500 slack/                        # Slack formatting and policy\n\u2502   \u251c\u2500\u2500 formatting.py\n\u2502   \u2514\u2500\u2500 policy.py\n\u251c\u2500\u2500 tools/                        # Core functionality\n\u2502   \u251c\u2500\u2500 warehouse.py              # Query execution via BSL\n\u2502   \u251c\u2500\u2500 semantic.py               # Semantic model lookups\n\u2502   \u251c\u2500\u2500 calculations.py           # Analytics helpers\n\u2502   \u2514\u2500\u2500 charts.py                 # Plotly chart generation\n\u251c\u2500\u2500 evals/                        # Test framework\n\u2502   \u251c\u2500\u2500 cases.py\n\u2502   \u251c\u2500\u2500 runner.py\n\u2502   \u2514\u2500\u2500 pydantic_adapter.py\n\u2514\u2500\u2500 scaffold/                     # Templates for falk init\n    \u251c\u2500\u2500 RULES.md\n    \u251c\u2500\u2500 falk_project.yaml\n    \u251c\u2500\u2500 semantic_models.yaml\n    \u251c\u2500\u2500 seed_data.py\n    \u2514\u2500\u2500 knowledge/\n\napp/                              \u2190 Application interfaces (thin wrappers)\n\u251c\u2500\u2500 web.py                        # Web UI (uvicorn)\n\u251c\u2500\u2500 slack.py                      # Slack bot (socket mode + markdown converter)\n\u2514\u2500\u2500 mcp.py                        # MCP server (FastMCP)\n</code></pre>"},{"location":"contributing/#key-principles","title":"Key principles","text":"<ul> <li>Library first \u2014 <code>src/falk/</code> is a pip-installable package. Everything else is a thin wrapper.</li> <li>Semantic layer driven \u2014 BSL YAML defines all data knowledge.</li> <li>Never invent numbers \u2014 all data comes from the database via tools.</li> <li>Context engineering \u2014 <code>RULES.md</code> + <code>knowledge/</code> teach the agent about your business.</li> <li>Two config files \u2014 <code>semantic_models.yaml</code> (data) + <code>falk_project.yaml</code> (technical).</li> <li>Testable \u2014 eval framework catches regressions.</li> </ul>"},{"location":"contributing/#running-locally","title":"Running locally","text":"<pre><code># Web UI\nfalk chat\n\n# Docs\nmkdocs build  # or mkdocs serve for local preview\n\n# Tests\npytest\n\n# Lint\nruff check .\n</code></pre>"},{"location":"contributing/#deploying-docs","title":"Deploying docs","text":"<pre><code>uv run mkdocs gh-deploy\n</code></pre>"},{"location":"why-falk/","title":"Why falk?","text":"<p>falk exists to answer a simple question:</p> <p>How can we let AI query our warehouse safely without breaking governance and trust?</p> <p>Most new agents start from \"let the model write SQL over your whole warehouse\". That\u2019s powerful, but it ignores how data teams actually work: governed metrics, curated models, and hard\u2011won trust in a handful of numbers (revenue, CAC, churn, etc.). falk is built to respect that reality.</p>"},{"location":"why-falk/#why-we-built-falk","title":"Why we built falk","text":""},{"location":"why-falk/#metrics-need-a-home-not-a-prompt","title":"Metrics need a home, not a prompt","text":"<p>In real companies, \"what is revenue?\" is not a prompt \u2014 it\u2019s a contract:</p> <ul> <li>Finance has a specific definition (filters, joins, time windows)</li> <li>BI dashboards use that same definition</li> <li>Teams get very upset if a new tool shows different numbers</li> </ul> <p>falk makes the semantic model the source of truth:</p> <ul> <li>Metrics and dimensions live in versioned YAML (semantic models)</li> <li>The agent reads those models instead of guessing from tables</li> <li>Every interface (Slack, CLI, web) uses the same definitions</li> </ul>"},{"location":"why-falk/#governance-cant-be-an-afterthought","title":"Governance can\u2019t be an afterthought","text":"<p>Letting an LLM query arbitrary tables is fine for exploration, but not for production analytics. We built falk so that:</p> <ul> <li>Only approved metrics/dimensions are exposed</li> <li>Access control can be enforced at the semantic layer</li> <li>You can reason about what the agent is allowed to know</li> </ul> <p>Instead of \"LLM + warehouse\", falk is LLM + semantic layer + warehouse.</p>"},{"location":"why-falk/#why-questions-should-be-firstclass","title":"\"Why\" questions should be first\u2011class","text":"<p>Most tools stop at \"what\":</p> <ul> <li>\"Revenue last month\"  </li> <li>\"Top 10 customers\"  </li> </ul> <p>But real conversations quickly become \"why\":</p> <ul> <li>\"Why did revenue go up?\"  </li> <li>\"Which segment drove the change?\"  </li> <li>\"Was it volume or price?\"  </li> </ul> <p>Because falk understands metrics and dimensions from the semantic layer, it can:</p> <ul> <li>Decompose metric changes across dimensions (regions, products, segments)</li> <li>Use related_metrics (e.g. revenue = orders \u00d7 AOV) to explain drivers</li> <li>Answer \"why\" with structure, not just more numbers</li> </ul>"},{"location":"why-falk/#agents-should-be-tools-not-monoliths","title":"Agents should be tools, not monoliths","text":"<p>We wanted something that works well in many contexts:</p> <ul> <li>CLI for project management and testing (<code>falk init</code>, <code>falk test</code>)</li> <li>Pydantic\u2011AI agent for conversational interfaces (Slack, web)</li> <li>Clear JSON outputs so other agents/orchestrators can treat falk as a governed data tool</li> </ul> <p>The design goal: falk is the data brain you plug other agents into, not another all\u2011in\u2011one assistant.</p>"},{"location":"why-falk/#what-falk-gives-you","title":"What falk gives you","text":"<ul> <li>Governed access \u2014 only metrics/dimensions you\u2019ve modeled</li> <li>Consistent numbers \u2014 same as your BI/semantic layer</li> <li>Context\u2011aware answers \u2014 uses descriptions, synonyms, gotchas</li> <li>Context\u2011aware answers \u2014 related metrics and formulas</li> <li>Tool\u2011first design \u2014 CLI and agent tools meant to be composed</li> </ul>"},{"location":"why-falk/#when-falk-makes-sense","title":"When falk makes sense","text":"<p>falk is built for teams that:</p> <ul> <li>Already have (or want) a semantic layer</li> <li>Care that \"revenue\" means the same thing everywhere</li> <li>Need AI to respect governance, not bypass it</li> <li>Want agents/skills that can safely answer data questions</li> </ul> <p>If you just want to let a model explore every table freely, falk is probably not the right choice. If you want governed AI access to trusted metrics, that\u2019s exactly what falk is for.</p>"},{"location":"why-falk/#inspiration-credits","title":"Inspiration &amp; Credits","text":"<p>falk was inspired by excellent work in the data agent space:</p> <ul> <li> <p>OpenAI's in-house data agent \u2014 Grounded metric querying and data agents.</p> </li> <li> <p>nao \u2014 Demonstrated the power of context engineering with file-system based context, unit testing for agent reliability, and the importance of versioning agent behavior. Their approach to organizing business context in structured files influenced falk's <code>knowledge/</code> and <code>RULES.md</code> design.</p> </li> <li> <p>dash \u2014 Showed how agents can learn from errors through \"6 layers of context\" and a feedback loop that captures learnings without retraining. Their focus on self-improvement influenced falk's evaluation framework and feedback collection.</p> </li> </ul> <p>We're grateful to these projects for pushing the boundaries of what data agents can do.</p> <p>Next: Quick Start \u2014 see what it feels like to define a metric once and query it everywhere.</p>"},{"location":"concepts/context-engineering/","title":"Context Engineering","text":"<p>falk uses layered context so teams can customize behavior without editing core code.</p>"},{"location":"concepts/context-engineering/#core-principle","title":"Core Principle","text":"<p>Put each type of information in one canonical place:</p> <ul> <li>Runtime config: <code>falk_project.yaml</code></li> <li>Behavior policy: <code>RULES.md</code></li> <li>Domain/company knowledge: <code>knowledge/business.md</code></li> <li>Data caveats: <code>knowledge/gotchas.md</code></li> <li>Metric/dimension definitions: <code>semantic_models.yaml</code></li> </ul> <p>This keeps prompts deterministic and easier to maintain across many companies.</p>"},{"location":"concepts/context-engineering/#load-model-phase-1","title":"Load Model (Phase 1)","text":"Source Loaded <code>falk_project.yaml</code> Startup <code>semantic_models.yaml</code> Startup <code>RULES.md</code> Startup (included in prompt) <code>knowledge/business.md</code> Startup when <code>agent.knowledge.enabled: true</code> <code>knowledge/gotchas.md</code> Startup when <code>agent.knowledge.enabled: true</code> <p><code>agent.knowledge.load_mode: on_demand</code> is reserved for future work.</p>"},{"location":"concepts/context-engineering/#prompt-precedence","title":"Prompt Precedence","text":"<p>When instructions conflict, precedence is:</p> <ol> <li>Built-in system prompt defaults</li> <li><code>RULES.md</code></li> <li>Inline project config (<code>agent.rules</code>, <code>agent.custom_sections</code>)</li> <li>Knowledge files (<code>knowledge/*.md</code>)</li> <li>Semantic metadata (synonyms, descriptions, gotchas)</li> </ol>"},{"location":"concepts/context-engineering/#what-goes-where","title":"What Goes Where","text":""},{"location":"concepts/context-engineering/#falk_projectyaml","title":"<code>falk_project.yaml</code>","text":"<p>Use for: - quick business summary (<code>agent.context</code>) - sample questions (<code>agent.examples</code>) - short project rules (<code>agent.rules</code>) - global caveats (<code>agent.gotchas</code>) - knowledge loading controls (<code>agent.knowledge</code>)</p>"},{"location":"concepts/context-engineering/#rulesmd","title":"<code>RULES.md</code>","text":"<p>Use for: - response/process standards that apply broadly - formatting expectations - escalation and error style</p> <p>Keep it concise and universal.</p>"},{"location":"concepts/context-engineering/#knowledgebusinessmd","title":"<code>knowledge/business.md</code>","text":"<p>Use for: - glossary and domain definitions - business model and customer journey - interpretation context</p>"},{"location":"concepts/context-engineering/#knowledgegotchasmd","title":"<code>knowledge/gotchas.md</code>","text":"<p>Use for: - data freshness notes - known quality gaps - caveats users should hear when relevant</p>"},{"location":"concepts/context-engineering/#semantic_modelsyaml","title":"<code>semantic_models.yaml</code>","text":"<p>Use for: - metric formulas - dimensions and joins - semantic synonyms - model metadata</p>"},{"location":"concepts/context-engineering/#why-this-matters","title":"Why This Matters","text":"<p>This separation improves: - consistency across companies/projects - maintenance and onboarding - prompt clarity and lower drift - reliable customization without code edits</p>"},{"location":"concepts/context-engineering/#phase-2-note","title":"Phase 2 Note","text":"<p>Access policy / row-level governance is intentionally deferred to phase 2.</p>"},{"location":"concepts/context-engineering/#see-also","title":"See also","text":"<ul> <li>Tuning the agent \u2014 improving answer quality (context, evals, model choice).</li> </ul>"},{"location":"concepts/evals/","title":"Testing &amp; Validation","text":"<p>Validate your project configuration, semantic models, and test that your agent gives correct answers.</p>"},{"location":"concepts/evals/#falk-validate-vs-falk-test","title":"<code>falk validate</code> vs <code>falk test</code>","text":"<p><code>falk validate</code> runs project/runtime checks:</p> <ol> <li>Configuration validation - Checks <code>falk_project.yaml</code> structure and required fields</li> <li>Semantic layer validation - Validates BSL models for errors, duplicates, missing fields</li> <li>Connection test - Verifies warehouse connectivity (optional with <code>--no-connection</code>)</li> <li>Agent initialization - Ensures agent can be built with current config</li> </ol> <p><code>falk test</code> runs behavior eval cases from <code>evals/</code>.</p> <p>Every time you update <code>semantic_models.yaml</code>, <code>RULES.md</code>, or context files, run <code>falk validate</code> first, then <code>falk test</code> for behavior checks.</p>"},{"location":"concepts/evals/#test-cases-yaml","title":"Test cases (YAML)","text":"<p>Define test cases in <code>evals/</code>:</p> <pre><code># evals/basic.yaml\n- question: \"What's our total revenue?\"\n  expected_tools:\n    - query_metric\n  expected_contains:\n    - \"revenue\"\n  expected_not_contains:\n    - \"I don't know\"\n\n- question: \"Show me revenue by region\"\n  expected_tools:\n    - query_metric\n  expected_kwargs:\n    group_by: [\"region\"]\n</code></pre> <p>Each test case specifies: - question \u2014 what the user asks - expected_tools \u2014 which tools should be called - expected_contains \u2014 strings that should appear in the response - expected_not_contains \u2014 strings that should NOT appear - expected_kwargs \u2014 expected arguments to tool calls</p>"},{"location":"concepts/evals/#running-evals","title":"Running evals","text":"<pre><code># Validate project/runtime\nfalk validate\n\n# Quick validation only (no connection test, no agent init)\nfalk validate --fast\n\n# Run all evals\nfalk test\n\n# Filter eval files\nfalk test --pattern \"*.yaml\"\n\n# Verbose output\nfalk test --verbose\n\n# Filter by tags\nfalk test --tags access,gotchas\n</code></pre>"},{"location":"concepts/evals/#writing-good-test-cases","title":"Writing good test cases","text":""},{"location":"concepts/evals/#start-with-real-questions","title":"Start with real questions","text":"<p>The best test cases come from actual user questions (especially ones that went wrong):</p> <pre><code># This failed before we added the \"sales\" synonym\n- question: \"What are our total sales?\"\n  expected_tools:\n    - query_metric\n  expected_contains:\n    - \"revenue\"\n</code></pre>"},{"location":"concepts/evals/#cover-edge-cases","title":"Cover edge cases","text":"<pre><code># Gotcha awareness\n- question: \"What was revenue yesterday?\"\n  expected_contains:\n    - \"delay\"  # Should mention the 48-hour delay\n\n# Entity resolution\n- question: \"Revenue for acme\"\n  expected_tools:\n    - lookup_values\n    - query_metric\n</code></pre>"},{"location":"concepts/evals/#keep-it-focused","title":"Keep it focused","text":"<p>Each test case should test ONE thing. Don't write tests that check everything at once.</p>"},{"location":"concepts/evals/#pydantic-evals-integration","title":"Pydantic Evals integration","text":"<p>For more advanced testing, falk includes a bridge to Pydantic Evals:</p> <pre><code>from falk.evals.pydantic_adapter import to_pydantic_evals_dataset\nfrom falk.evals.cases import load_cases\n\ncases = load_cases(\"evals/basic.yaml\")\ndataset = to_pydantic_evals_dataset(cases)\n</code></pre> <p>This lets you use Pydantic Evals' richer assertion system alongside the YAML-based cases.</p>"},{"location":"concepts/evals/#ci-integration","title":"CI integration","text":"<p>Add evals to your CI pipeline:</p> <pre><code># .github/workflows/evals.yml\nname: Run Evals\non: [pull_request]\n\njobs:\n  evals:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n      - run: pip install -e .\n      - run: falk test --verbose\n        env:\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n</code></pre>"},{"location":"concepts/evals/#langfuse-for-production-evaluation","title":"LangFuse for production evaluation","text":"<p>For production, use LangFuse's LLM-as-a-judge evaluations:</p> <ul> <li>Evals (YAML) \u2192 local testing, CI, regression catching</li> <li>LangFuse \u2192 production monitoring, feedback analysis, prompt evaluation</li> </ul> <p>See Logfire Observability for setup.</p>"},{"location":"concepts/how-it-works/","title":"How It Works","text":""},{"location":"concepts/how-it-works/#architecture","title":"Architecture","text":"<pre><code>User (Slack / Web UI / CLI)\n     \u2502\n     \u25bc\nPydantic AI Agent\n     \u2502\n     \u251c\u2500\u2500 System Prompt (auto-generated from RULES.md + semantic models)\n     \u251c\u2500\u2500 Tools (query, export, chart, metadata)\n     \u2502     \u2502\n     \u2502     \u25bc\n     \u2502   BSL Semantic Layer \u2192 Database\n     \u2502\n     \u2514\u2500\u2500 Feedback \u2192 LangFuse (optional)\n</code></pre>"},{"location":"concepts/how-it-works/#flow","title":"Flow","text":"<ol> <li>User asks a question \u2014 \"top 10 regions by sales last month\"</li> <li>Agent reads system prompt \u2014 includes RULES.md, business context, synonyms, gotchas</li> <li>Agent resolves vocabulary \u2014 \"sales\" \u2192 <code>revenue</code> (from synonyms)</li> <li>Agent calls tools \u2014 <code>query_metric(metric=\"revenue\", group_by=[\"region\"], order=\"desc\", limit=10)</code></li> <li>BSL generates the query \u2014 from semantic model definitions</li> <li>Database executes \u2014 returns data</li> <li>Agent checks gotchas \u2014 e.g., \"Revenue has a 48-hour delay\"</li> <li>Agent formats response \u2014 Slack-optimised (bullets, bold, no tables)</li> <li>User reacts \u2014 feedback sent to LangFuse</li> </ol>"},{"location":"concepts/how-it-works/#the-knowledge-layer","title":"The knowledge layer","text":"<p>The system prompt is assembled automatically from three sources:</p> Source What it contributes <code>semantic_models.yaml</code> Metrics, dimensions, synonyms, gotchas <code>RULES.md</code> Agent behavior, tone, orchestration rules <code>knowledge/</code> Domain knowledge (loaded at startup when enabled) <p>You never edit the prompt directly. Update your config files and the prompt updates itself.</p>"},{"location":"concepts/how-it-works/#gotchas","title":"Gotchas","text":"<p>Gotchas are injected into the system prompt so the agent can proactively warn users:</p> <pre><code>measures:\n  revenue:\n    expr: _.revenue.sum()\n    gotchas: \"Revenue has a 48-hour reporting delay\"\n</code></pre> <p>When someone asks \"what was our revenue yesterday?\", the agent mentions the delay.</p>"},{"location":"concepts/how-it-works/#entity-resolution","title":"Entity resolution","text":"<p>When a user says \"sales for Acme Corp\", the agent:</p> <ol> <li>Calls <code>lookup_values(\"customer\", \"Acme Corp\")</code> \u2014 fuzzy search</li> <li>Gets the exact match</li> <li>Uses it as a filter</li> </ol> <p>Works for partial matches too \u2014 \"acme\" finds \"Acme Corp\".</p>"},{"location":"concepts/how-it-works/#conversational-delivery","title":"Conversational delivery","text":"<p>Large results don't get dumped:</p> <ul> <li>\u226410 rows \u2192 shown inline</li> <li>&gt;10 rows \u2192 preview + \"Want top 10? Export to CSV? Chart?\"</li> </ul> <p>The agent asks how you want to consume the data.</p>"},{"location":"concepts/learning/","title":"Knowledge &amp; Feedback","text":"<p>The agent learns from config files and context. It improves over time through a feedback loop.</p>"},{"location":"concepts/learning/#what-the-agent-knows","title":"What the agent knows","text":""},{"location":"concepts/learning/#1-vocabulary-semantic_modelsyaml","title":"1. Vocabulary \u2014 <code>semantic_models.yaml</code>","text":"<pre><code>measures:\n  revenue:\n    expr: _.revenue.sum()\n    synonyms: [\"sales\", \"income\", \"turnover\"]\ndimensions:\n  region:\n    expr: _.region\n    synonyms: [\"territory\", \"area\"]\n</code></pre>"},{"location":"concepts/learning/#2-gotchas-semantic_modelsyaml","title":"2. Gotchas \u2014 <code>semantic_models.yaml</code>","text":"<pre><code>measures:\n  revenue:\n    gotchas: \"Revenue has a 48-hour reporting delay\"\n</code></pre> <p>The agent proactively mentions these when relevant.</p>"},{"location":"concepts/learning/#3-behavior-rulesmd","title":"3. Behavior \u2014 <code>RULES.md</code>","text":"<p>Tone, SQL style, privacy rules, orchestration:</p> <pre><code>## Orchestration\nFor business context: Read `knowledge/business.md`\nFor data quality notes: Read `knowledge/gotchas.md`\n</code></pre>"},{"location":"concepts/learning/#4-domain-knowledge-knowledge","title":"4. Domain knowledge \u2014 <code>knowledge/</code>","text":"<p>Detailed knowledge loaded on demand:</p> <ul> <li><code>knowledge/business.md</code> \u2014 business terms, company context</li> <li><code>knowledge/gotchas.md</code> \u2014 known data issues</li> </ul> <p>See Context Engineering.</p>"},{"location":"concepts/learning/#feedback-loop","title":"Feedback loop","text":"<pre><code>User asks question\n     \u2193\nAgent answers \u2192 trace in LangFuse\n     \u2193\nUser reacts \ud83d\udc4d or \ud83d\udc4e \u2192 score in LangFuse\n     \u2193\nData steward reviews low scores\n     \u2193\nUpdates config/context files \u2192 agent improves\n</code></pre>"},{"location":"concepts/learning/#the-improvement-cycle","title":"The improvement cycle","text":"<ol> <li>Find issues \u2014 filter LangFuse traces by low scores</li> <li>Understand why \u2014 see the full trace (query \u2192 tools \u2192 response)</li> <li>Fix the source \u2014 update synonyms, gotchas, rules, or context</li> <li>Write a test \u2014 add a case to <code>evals/</code> to prevent regression</li> <li>Verify \u2014 <code>falk test</code></li> </ol>"},{"location":"concepts/learning/#everything-is-files","title":"Everything is files","text":"<p>All agent knowledge lives in version-controlled files:</p> File Purpose <code>semantic_models.yaml</code> Data definitions + synonyms + gotchas <code>falk_project.yaml</code> Technical configuration <code>RULES.md</code> Agent behavior <code>knowledge/</code> Domain knowledge <p>No database. No migrations. PR-reviewed and version-controlled.</p>"},{"location":"concepts/metric-decomposition/","title":"Metric Decomposition","text":"<p>Metric decomposition (automatic root cause analysis) is not available in this version.</p> <p>To compare metrics across time periods, use <code>query_metric</code> with <code>compare_period=\"week\"|\"month\"|\"quarter\"</code>. To see where change happened, use <code>query_metric</code> with <code>group_by</code> on dimensions (e.g. region, product).</p>"},{"location":"concepts/tools/","title":"Agent Tools","text":"<p>The agent has tools the LLM can call. Users don't see tool names \u2014 they just ask questions in natural language.</p>"},{"location":"concepts/tools/#custom-tool-extensions","title":"Custom Tool Extensions","text":"<p>You can add project-specific Python tools in your falk project and register them via <code>falk_project.yaml</code>. Tool logic stays in Python; YAML only registers which modules to load.</p>"},{"location":"concepts/tools/#configure","title":"Configure","text":"<p>In <code>falk_project.yaml</code> under <code>agent</code>:</p> <pre><code>agent:\n  extensions:\n    tools:\n      - module: project_tools.customer_health\n      - module: project_tools.forecasting\n      - module: project_tools.alerts\n        enabled: false   # optional: disable without removing\n</code></pre>"},{"location":"concepts/tools/#implement","title":"Implement","text":"<p>Create a Python module in your project (e.g. <code>project_tools/customer_health.py</code>) that exports a <code>FunctionToolset</code> instance as <code>toolset</code>, <code>data_tools</code>, or <code>tools</code>:</p> <pre><code>from pydantic_ai import FunctionToolset, RunContext\nfrom falk.agent import DataAgent\n\ntoolset = FunctionToolset()\n\n@toolset.tool\ndef customer_health_score(ctx: RunContext[DataAgent], customer_id: str) -&gt; dict:\n    \"\"\"Compute health score for a customer.\"\"\"\n    # Use ctx.deps for DataAgent (warehouse, metrics, etc.)\n    agent = ctx.deps\n    # ... your logic ...\n    return {\"score\": 0.85, \"trend\": \"up\"}\n</code></pre>"},{"location":"concepts/tools/#runtime-behavior","title":"Runtime behavior","text":"<ul> <li>Custom tools are loaded at startup when the agent or MCP server starts.</li> <li>Invalid or missing modules log warnings and are skipped; built-in tools remain available.</li> <li>Tools are exposed in both the agent (chat, web, Slack) and the MCP server.</li> </ul>"},{"location":"concepts/tools/#testing","title":"Testing","text":"<ol> <li>Unit tests: Call each tool function directly with a mock <code>ctx</code> (e.g. <code>ctx.deps = DataAgent()</code>).</li> <li>Integration tests: Run <code>agent.run_sync(\"question\")</code> and assert the model uses the right tool.</li> <li>Evals: Add <code>evals/</code> cases for user phrasing that should trigger your custom tools.</li> </ol> <p>See Project Config for the full config schema.</p>"},{"location":"concepts/tools/#data-querying","title":"Data Querying","text":"Tool What it does <code>query_metric</code> Query metrics with optional group_by, filters, time_grain, order, limit, compare_period, include_share <code>lookup_values</code> Find actual values in a dimension (fuzzy search)"},{"location":"concepts/tools/#query_metric-the-main-tool","title":"<code>query_metric</code> \u2014 The main tool","text":"<pre><code>query_metric(\n    metrics=[\"revenue\"],\n    group_by=[\"customer\"],\n    time_grain=\"month\",\n    filters=[{\"field\": \"customer\", \"op\": \"=\", \"value\": \"Acme Corp\"}],\n    order=\"desc\",\n    limit=10,\n    compare_period=\"month\",   # optional: week | month | quarter\n    include_share=True,       # optional: add share_pct column\n)\n</code></pre>"},{"location":"concepts/tools/#export","title":"Export","text":"Tool What it does <code>export(format)</code> Export last result (format: csv | excel | sheets) <code>generate_chart</code> Generate a Plotly chart (bar, line, pie) <p>In Slack, exported files are uploaded directly to the channel.</p>"},{"location":"concepts/tools/#date-ranges","title":"Date Ranges","text":"Tool What it does <code>suggest_date_range(period)</code> Get date range for common periods: yesterday, today, last_7_days, last_30_days, this_week, this_month, last_month, this_quarter"},{"location":"concepts/tools/#metadata-discovery","title":"Metadata / Discovery","text":"Tool What it does <code>list_catalog(entity_type)</code> List metrics and/or dimensions (entity_type: metric | dimension | both) <code>describe_metric</code> Get metric details (description, dimensions, time grains) <code>describe_model</code> Get full semantic model description <code>describe_dimension</code> Get dimension meaning (helps with disambiguation) <code>disambiguate(entity_type, concept)</code> Find metrics/dimensions matching a concept; use when the user's request is ambiguous to ask a clarification question"},{"location":"concepts/tools/#interface-naming-note","title":"Interface Naming Note","text":"<ul> <li>Agent interface tool: <code>lookup_values(dimension, search)</code></li> <li>MCP interface tool: <code>lookup_dimension_values(dimension, search)</code></li> <li>They expose the same lookup capability with interface-specific names.</li> </ul>"},{"location":"concepts/tools/#chart-auto-detection","title":"Chart Auto-Detection","text":"<p>When the user asks for a chart without specifying a type, the agent picks the best one:</p> Data shape Chart type Time dimension present Line chart 2\u20138 categories Pie chart 9+ categories Bar chart <p>Users can override: \"show me a bar chart\" or \"make it a pie chart\".</p>"},{"location":"configuration/","title":"Configuration","text":"<p>falk uses files, not databases. All configuration is version-controlled and PR-reviewable.</p> File Purpose Loaded When Who Edits <code>falk_project.yaml</code> LLM settings, session config, quick context Startup Platform team <code>semantic_models.yaml</code> Metrics, dimensions, data structure Startup Data engineers <code>RULES.md</code> Agent behavior, tone, formatting Every message Anyone <code>knowledge/business.md</code> Business terms, glossary, company context Startup (if enabled) Domain experts <code>knowledge/gotchas.md</code> Data quality issues, caveats Startup (if enabled) Data stewards <code>.env</code> API keys, secrets Startup DevOps"},{"location":"configuration/#what-goes-where","title":"What Goes Where?","text":"<p>\"What LLM should we use?\" \u2192 <code>falk_project.yaml</code> \"Revenue = SUM(orders.amount)\" \u2192 <code>semantic_models.yaml</code> \"Always use nested bullets\" \u2192 <code>RULES.md</code> \"MRR = monthly recurring revenue\" \u2192 <code>knowledge/business.md</code> \"Revenue delayed 24h\" \u2192 <code>knowledge/gotchas.md</code> \"Be conversational, not robotic\" \u2192 <code>RULES.md</code> Example questions \u2192 <code>falk_project.yaml</code> Custom project tools \u2192 <code>falk_project.yaml</code> (<code>agent.extensions.tools</code>) + Python modules  </p> <p>See Context Engineering for detailed guidance.</p>"},{"location":"configuration/#how-it-fits-together","title":"How It Fits Together","text":"<pre><code>semantic_models.yaml    \u2192  \"What data exists\" (metrics, dimensions)\nfalk_project.yaml       \u2192  \"How the agent runs\" (LLM, session store)\nRULES.md                \u2192  \"How the agent behaves\" (always included)\nknowledge/              \u2192  \"Deep domain knowledge\" (startup when enabled)\n</code></pre> <p>Update any config file and the agent picks up the changes automatically \u2014 no prompt editing needed.</p>"},{"location":"configuration/#reference","title":"Reference","text":"<ul> <li>Semantic Models \u2014 metrics, dimensions, synonyms, gotchas</li> <li>Project Config \u2014 LLM provider, session store, extensions, runtime settings</li> <li>Agent Tools \u2014 built-in tools and custom extensions</li> <li>Metric Relationships \u2014 define how metrics relate</li> <li>LLM Providers \u2014 OpenAI, Anthropic, Gemini setup</li> </ul>"},{"location":"configuration/agent/","title":"Project Configuration","text":"<p><code>falk_project.yaml</code> is the canonical runtime configuration for falk. It controls model behavior, prompt extensions, session storage, observability, and runtime limits.</p>"},{"location":"configuration/agent/#canonical-config-surface","title":"Canonical Config Surface","text":"<pre><code>version: 1\n\nconnection:\n  type: duckdb\n  database: data/warehouse.duckdb\n\nagent:\n  provider: openai\n  model: gpt-5-mini\n  context: |\n    We are a B2B SaaS company selling analytics software.\n\n  examples:\n    - \"What is revenue by region this month?\"\n    - \"Top 5 customers by revenue\"\n\n  rules:\n    - \"Always mention the date range used.\"\n    - \"Revenue has a 24-hour delay.\"\n\n  gotchas:\n    - \"Data from today may be incomplete before daily refresh.\"\n\n  welcome: |\n    Hi! I can help you explore your data.\n\n  custom_sections:\n    - title: Reporting Conventions\n      content: |\n        - Use USD unless requested otherwise.\n        - Round percentages to one decimal place.\n\n  knowledge:\n    enabled: true\n    business_path: knowledge/business.md\n    gotchas_path: knowledge/gotchas.md\n    load_mode: startup   # startup (phase 1), on_demand reserved\n\n  # Custom Python tool extensions (see concepts/tools.md)\n  extensions:\n    tools:\n      - module: project_tools.customer_health\n      - module: project_tools.forecasting\n      - module: project_tools.alerts\n        enabled: false\n\n# Observability: set LOGFIRE_TOKEN in .env for Logfire Cloud tracing (optional)\n\nsession:\n  store: postgres       # postgres (default) or memory (dev fallback)\n  postgres_url: ${POSTGRES_URL}\n  schema: falk_session\n  ttl: 3600\n  maxsize: 500\n\nslack:\n  exports_dm_only: true\n  export_channel_allowlist: []   # optional channel IDs allowed for exports\n  export_block_message: \"Export files are restricted to DMs. Ask me in DM if you need the file.\"\n\npaths:\n  semantic_models: semantic_models.yaml\n\nadvanced:\n  auto_run: false                 # reserved for future use\n  max_tokens: 4096\n  temperature: 0.1\n  max_rows_per_query: 10000\n  query_timeout_seconds: 30       # warehouse/tool execution\n  model_timeout_seconds: 60       # LLM request (single turn)\n  max_retries: 3\n  retry_delay_seconds: 1\n  log_level: INFO\n</code></pre>"},{"location":"configuration/agent/#what-is-applied-at-runtime","title":"What Is Applied at Runtime","text":""},{"location":"configuration/agent/#agent","title":"<code>agent</code>","text":"<ul> <li><code>context</code>, <code>examples</code>, <code>rules</code>, <code>gotchas</code>, <code>welcome</code>, and <code>custom_sections</code> are injected into prompt construction.</li> <li><code>knowledge.*</code> controls startup loading of <code>knowledge/business.md</code> and <code>knowledge/gotchas.md</code>.</li> <li><code>extensions.tools</code> registers custom Python tool modules. Each module must export a <code>FunctionToolset</code> (as <code>toolset</code>, <code>data_tools</code>, or <code>tools</code>). Tools are loaded at startup and exposed in both the agent (chat, web, Slack) and MCP server. See Custom Tool Extensions.</li> </ul>"},{"location":"configuration/agent/#advanced","title":"<code>advanced</code>","text":"<ul> <li><code>max_tokens</code>, <code>temperature</code>, <code>model_timeout_seconds</code>, and <code>max_retries</code> are applied to model execution (LLM request timeout).</li> <li><code>query_timeout_seconds</code> is the timeout for tool execution (e.g. warehouse queries); tune it separately from <code>model_timeout_seconds</code> if you see \"query took too long\" from slow DB vs slow model.</li> <li><code>slack_run_timeout_seconds</code> is the timeout for a whole Slack run (model + tools), used by the Slack bot's outer <code>future.result(timeout=...)</code>.</li> <li><code>tool_calls_limit</code> is the maximum number of tool calls allowed per run; lower values stop tool loops sooner.</li> <li><code>request_limit</code> is the maximum number of LLM turns per run.</li> <li><code>max_rows_per_query</code> and retry settings are enforced in warehouse query execution.</li> <li><code>log_level</code> and timeout settings are applied in Slack runtime behavior.</li> <li><code>auto_run</code> is reserved for future use.</li> </ul>"},{"location":"configuration/agent/#session","title":"<code>session</code>","text":"<ul> <li><code>postgres</code> for production (default). Requires <code>POSTGRES_URL</code> in <code>.env</code>. Falk creates schema and tables automatically.</li> <li><code>memory</code> for dev fallback when <code>POSTGRES_URL</code> is not set.</li> <li>Session config precedence is: environment variables &gt; <code>falk_project.yaml</code> &gt; defaults.</li> <li><code>SESSION_STORE</code>, <code>POSTGRES_URL</code>, <code>SESSION_SCHEMA</code>, <code>SESSION_TTL</code>, <code>SESSION_MAXSIZE</code></li> <li>Persisted session state is JSON-only (<code>last_query_data</code>, <code>last_query_metric</code>, <code>pending_files</code>).</li> <li>Chart aggregate objects are process-local and ephemeral; if unavailable (restart/worker switch), rerun <code>query_metric</code> before <code>generate_chart</code>.</li> </ul>"},{"location":"configuration/agent/#slack","title":"<code>slack</code>","text":"<ul> <li><code>exports_dm_only: true</code> blocks export/chart file uploads in non-DM channels.</li> <li><code>export_channel_allowlist</code> can allow specific channel IDs when you decide to widen policy.</li> <li><code>export_block_message</code> controls the user-visible notice shown when export delivery is blocked in-channel.</li> </ul>"},{"location":"configuration/agent/#observability","title":"Observability","text":"<ul> <li>Set <code>LOGFIRE_TOKEN</code> in <code>.env</code> to enable Logfire Cloud tracing and feedback (optional).</li> </ul>"},{"location":"configuration/agent/#paths","title":"<code>paths</code>","text":"<ul> <li><code>paths.semantic_models</code> controls semantic model file resolution.</li> </ul>"},{"location":"configuration/agent/#connection","title":"<code>connection</code>","text":"<ul> <li>Inline database connection profile consumed by BSL.</li> </ul>"},{"location":"configuration/agent/#related-files","title":"Related Files","text":"File Purpose Loaded <code>falk_project.yaml</code> Canonical config and short inline context Startup <code>semantic_models.yaml</code> Metrics, dimensions, synonyms, model metadata Startup <code>RULES.md</code> Organization-wide response/process policy Startup (included in prompt) <code>knowledge/business.md</code> Domain/company context Startup when <code>agent.knowledge.enabled: true</code> <code>knowledge/gotchas.md</code> Data caveats and known issues Startup when <code>agent.knowledge.enabled: true</code> <code>.env</code> Secrets Startup"},{"location":"configuration/agent/#phase-2-note","title":"Phase 2 Note","text":"<p>Access policy / row-level governance is intentionally deferred to phase 2.</p>"},{"location":"configuration/llm-providers/","title":"LLM Providers","text":"<p>falk supports multiple LLM providers through Pydantic AI. Choose the provider that best fits your needs.</p>"},{"location":"configuration/llm-providers/#supported-providers","title":"Supported Providers","text":"Provider Model Format API Key Env Var Example Models OpenAI <code>openai:MODEL</code> <code>OPENAI_API_KEY</code> <code>gpt-5-mini</code>, <code>gpt-5</code>, <code>gpt-5.2</code> Anthropic <code>anthropic:MODEL</code> <code>ANTHROPIC_API_KEY</code> <code>claude-3-5-sonnet-20241022</code>, <code>claude-3-opus</code>, <code>claude-3-haiku</code> Google <code>google-genai:MODEL</code> <code>GOOGLE_API_KEY</code> <code>gemini-1.5-pro</code>, <code>gemini-1.5-flash</code>, <code>gemini-pro</code>"},{"location":"configuration/llm-providers/#configuration","title":"Configuration","text":""},{"location":"configuration/llm-providers/#1-set-provider-and-model","title":"1. Set Provider and Model","text":"<p>Set <code>agent.provider</code> and <code>agent.model</code> in <code>falk_project.yaml</code>:</p> <pre><code>agent:\n  provider: openai   # openai, anthropic, gemini, mistral\n  model: gpt-5-mini  # or gpt-5.2, claude-3-5-sonnet-20241022, gemini-1.5-pro, etc.\n</code></pre>"},{"location":"configuration/llm-providers/#2-set-your-api-key","title":"2. Set Your API Key","text":"<p>Set the API key for your chosen provider:</p> <pre><code># For OpenAI\nOPENAI_API_KEY=sk-...\n\n# For Anthropic\nANTHROPIC_API_KEY=sk-ant-...\n\n# For Google\nGOOGLE_API_KEY=...\n</code></pre>"},{"location":"configuration/llm-providers/#model-selection-guide","title":"Model Selection Guide","text":"<p>Cost-effective: - OpenAI: <code>gpt-5-mini</code> - Anthropic: <code>claude-3-haiku</code> - Google: <code>gemini-1.5-flash</code></p> <p>Balanced: - OpenAI: <code>gpt-5</code> - Anthropic: <code>claude-3-5-sonnet</code> - Google: <code>gemini-1.5-pro</code></p> <p>Best quality: - OpenAI: <code>gpt-5.2</code> - Anthropic: <code>claude-3-opus</code> - Google: <code>gemini-1.5-pro</code> (latest)</p>"},{"location":"configuration/llm-providers/#provider-specific-notes","title":"Provider-Specific Notes","text":""},{"location":"configuration/llm-providers/#openai","title":"OpenAI","text":"<ul> <li>Fast and reliable</li> <li>Good tool calling support</li> <li>Default choice for most use cases</li> </ul>"},{"location":"configuration/llm-providers/#anthropic-claude","title":"Anthropic Claude","text":"<ul> <li>Excellent reasoning capabilities</li> <li>Great for complex analytical queries</li> <li>Strong instruction following</li> </ul>"},{"location":"configuration/llm-providers/#google-gemini","title":"Google Gemini","text":"<ul> <li>Good multilingual support</li> <li>Competitive pricing</li> <li>Fast response times</li> </ul>"},{"location":"configuration/llm-providers/#troubleshooting","title":"Troubleshooting","text":"<p>\"No API key found\" - Make sure you've set the correct API key for your chosen provider - Check that the key is in your <code>.env</code> file or environment</p> <p>\"Model not found\" - Verify the model name is correct for your provider - Check Pydantic AI docs for the latest model names</p> <p>\"Provider not supported\" - Ensure you have the latest version of <code>pydantic-ai-slim</code> - Some providers may require additional dependencies</p>"},{"location":"configuration/llm-providers/#see-also","title":"See Also","text":"<ul> <li>Pydantic AI Models Reference \u2014 Complete list of all supported models and providers</li> <li>Pydantic AI Documentation \u2014 General Pydantic AI documentation</li> <li>Installation Guide \u2014 Setup instructions</li> </ul>"},{"location":"configuration/metric-relationships/","title":"Metric Relationships","text":"<p>Help the agent answer \"why\" questions by defining how metrics relate.</p> <p>When users ask \"Why did revenue increase?\", they want to understand: - WHERE the change happened (dimensions \u2192 use <code>query_metric</code> with <code>group_by</code>) - HOW the change happened (underlying metrics \u2192 handled by relationships)</p>"},{"location":"configuration/metric-relationships/#configuration","title":"Configuration","text":"<p>Add <code>related_metrics</code> and optionally <code>formula</code> to your metrics in <code>semantic_models.yaml</code>:</p> <pre><code>measures:\n  revenue:\n    expr: _.revenue.sum()\n    description: \"Total revenue\"\n    related_metrics:\n      - orders\n      - average_order_value\n    formula: \"orders \u00d7 average_order_value\"\n\n  orders:\n    expr: _.orders.sum()\n    description: \"Number of orders\"\n\n  average_order_value:\n    expr: _.revenue.sum() / _.orders.sum()\n    description: \"Average value per order\"\n</code></pre> <p>The agent reads <code>related_metrics</code>, queries them for the same period, and presents the complete picture.</p>"},{"location":"configuration/metric-relationships/#examples","title":"Examples","text":""},{"location":"configuration/metric-relationships/#e-commerce","title":"E-commerce","text":"<pre><code>revenue:\n  related_metrics: [orders, average_order_value]\n  formula: \"orders \u00d7 average_order_value\"\n\nprofit:\n  related_metrics: [revenue, costs]\n  formula: \"revenue - costs\"\n</code></pre>"},{"location":"configuration/metric-relationships/#saas","title":"SaaS","text":"<pre><code>mrr:\n  related_metrics: [active_subscriptions, arpu]\n  formula: \"active_subscriptions \u00d7 arpu\"\n\nnet_new_mrr:\n  related_metrics: [new_mrr, churned_mrr, expansion_mrr]\n  formula: \"new_mrr - churned_mrr + expansion_mrr\"\n</code></pre>"},{"location":"configuration/metric-relationships/#multi-model-business","title":"Multi-model business","text":"<p>For businesses where drivers vary by dimension (e.g., subscription vs advertising), use descriptions:</p> <pre><code>revenue:\n  description: |\n    Revenue drivers vary by site:\n    - Site A (subscription): subscribers \u00d7 price\n    - Site B (advertising): impressions \u00d7 cpm\n    - Site C (ecommerce): transactions \u00d7 aov\n  related_metrics:\n    - active_subscribers\n    - subscription_price\n    - total_impressions\n    - cpm\n    - transactions\n    - average_order_value\n</code></pre> <p>The agent reads the description and adapts its analysis to the relevant segment.</p>"},{"location":"configuration/metric-relationships/#how-the-agent-uses-it","title":"How the agent uses it","text":"<p>When a user asks \"Why did revenue increase?\":</p> <ol> <li>Decompose by dimensions \u2014 which regions/products/segments drove the change</li> <li>Check <code>related_metrics</code> \u2014 query orders and AOV for the same period</li> <li>Present both: WHERE (dimensions) and HOW (related metrics)</li> </ol> <p>No additional prompting needed \u2014 just define the relationships in your semantic models.</p>"},{"location":"configuration/metric-relationships/#best-practices","title":"Best practices","text":"<ul> <li>Start simple \u2014 begin with the obvious relationships (revenue = orders \u00d7 AOV)</li> <li>Keep lists short \u2014 2\u20134 related metrics per parent; too many makes output noisy</li> <li>Add formulas \u2014 optional but helpful for the agent and for documentation</li> <li>Don't overthink it \u2014 focus on metrics users frequently ask \"why\" about</li> </ul>"},{"location":"configuration/metric-relationships/#related","title":"Related","text":"<ul> <li>Semantic Models \u2014 full configuration guide</li> </ul>"},{"location":"configuration/semantic-models/","title":"Semantic Models","text":"<p><code>semantic_models.yaml</code> (in project root) is the single source of truth for the data agent. It defines what tables, metrics, and dimensions exist using the Boring Semantic Layer (BSL) YAML format.</p>"},{"location":"configuration/semantic-models/#format","title":"Format","text":"<pre><code>model_name:\n  table: duckdb_table_name\n  database: [schema_name]          # optional\n  description: \"What this model represents\"\n  dimensions:\n    dimension_name:\n      display_name: \"Dimension Name\"  # business-friendly label (optional)\n      expr: _.column_name           # ibis deferred expression\n      description: \"What this dimension means\"\n      is_time_dimension: true       # mark date/time columns\n      is_entity: true               # mark entity columns (for fuzzy matching)\n      data_domain: \"sales\"          # optional: core, sales, finance, etc.\n      synonyms: [\"alias1\", \"alias2\"]  # optional: terms your team uses\n      gotchas: \"Known data quirk\"    # optional: data quality warning\n  measures:\n    measure_name:\n      expr: _.column.sum()          # ibis aggregation expression\n      description: \"What this metric measures\"\n      synonyms: [\"alias1\", \"alias2\"]  # optional: terms your team uses\n      gotchas: \"Known data quirk\"    # optional: data quality warning\n</code></pre>"},{"location":"configuration/semantic-models/#display-names","title":"Display Names","text":"<p>Use <code>display_name</code> to provide business-friendly labels for dimensions:</p> <pre><code>dimensions:\n  customer_segment:\n    display_name: \"Customer Segment\"  # Shows as \"Customer Segment\" not \"customer_segment\"\n    expr: _.customer_segment\n    description: \"Customer segment (Enterprise, SMB, Consumer)\"\n\n  product_category:\n    display_name: \"Product Category\"\n    expr: _.product_category\n    description: \"Product category (Electronics, Clothing, etc.)\"\n</code></pre> <p>Best practice: Always add <code>display_name</code> as the first property (before <code>expr</code>) for readability.</p> <p>How it appears: - With <code>display_name</code>: \"Customer Segment\" (<code>customer_segment</code>) - Without <code>display_name</code>: \"customer_segment\"</p> <p>The technical name is still used for SQL queries, but users see the friendly label.</p>"},{"location":"configuration/semantic-models/#synonyms","title":"Synonyms","text":"<p>Add <code>synonyms</code> to any metric or dimension so the agent understands your team's everyday terminology:</p> <pre><code>measures:\n  revenue:\n    expr: _.revenue.sum()\n    description: \"Total revenue in USD\"\n    synonyms: [\"sales\", \"income\", \"turnover\"]\n\ndimensions:\n  region:\n    expr: _.region\n    description: \"Sales region\"\n    synonyms: [\"territory\", \"area\", \"market\"]\n</code></pre> <p>When a user says \"sales\" or \"turnover\", the agent automatically maps it to the <code>revenue</code> metric.</p> <p>Synonyms are:</p> <ul> <li>Version-controlled \u2014 reviewed via PR, shared across the team</li> <li>Injected into the system prompt \u2014 the LLM sees them on every query</li> <li>Low maintenance \u2014 add them once, they work forever</li> </ul>"},{"location":"configuration/semantic-models/#example","title":"Example","text":"<pre><code>sales_metrics:\n  table: sales_fact\n  database: [main]\n  description: \"E-commerce sales data with revenue, orders, and customer metrics\"\n\n  dimensions:\n    date:\n      display_name: \"Date\"\n      expr: _.date\n      description: \"Transaction date\"\n      is_time_dimension: true\n\n    region:\n      display_name: \"Region\"\n      expr: _.region\n      description: \"Sales region (US, EU, APAC, LATAM)\"\n      synonyms: [\"territory\", \"area\", \"market\"]\n      gotchas: \"LATAM data only available from 2025-06 onwards\"\n\n  measures:\n    revenue:\n      expr: _.revenue.sum()\n      description: \"Total revenue in USD\"\n      synonyms: [\"sales\", \"income\", \"turnover\"]\n      gotchas: \"Revenue has a 48-hour reporting delay\"\n</code></pre> <p>When someone asks \"what was our revenue yesterday?\", the agent will mention the delay. When someone queries LATAM data before June 2025, it'll flag the availability gap.</p> <p>For global data quality notes, document them in <code>knowledge/gotchas.md</code> or <code>RULES.md</code>. See Context Engineering.</p>"},{"location":"configuration/semantic-models/#what-gets-auto-generated","title":"What gets auto-generated","text":"<p>From this YAML, the agent automatically creates:</p> <ul> <li>System prompt \u2014 model summaries, key concepts, dimension glossary, vocabulary, gotchas</li> <li>Tool behavior \u2014 which metrics/dimensions are queryable</li> <li>Entity resolution \u2014 fuzzy matching on <code>is_entity</code> dimensions</li> <li>Disambiguation hints \u2014 for similar dimensions (e.g., different \"country\" fields)</li> </ul>"},{"location":"configuration/semantic-models/#tips","title":"Tips","text":"<p>Descriptions matter</p> <p>Write clear, concise descriptions. They appear in the system prompt and help the LLM understand your data. First sentence should explain the concept; examples help a lot.</p> <p>Use <code>synonyms</code></p> <p>Add synonyms for any metric or dimension where your team uses different terminology than the data model. This is the easiest way to improve the agent's understanding.</p> <p>Use <code>gotchas</code></p> <p>Add gotchas for data quirks your team keeps running into \u2014 delays, coverage gaps, known issues. The agent will warn users proactively instead of returning confusing results.</p> <p>Use <code>data_domain</code></p> <p>Adding <code>data_domain: \"sales\"</code> to dimensions helps the agent group related concepts and can be used to filter <code>list_dimensions(domain=\"sales\")</code>.</p> <p>Mark time dimensions</p> <p>Always set <code>is_time_dimension: true</code> on date columns \u2014 this enables time-grain queries (\"by day\", \"by month\") and period comparisons.</p>"},{"location":"configuration/tuning/","title":"Tuning the Agent","text":"<p>Improving answer quality is usually more about context, policy, and evaluation than swapping to a larger model. This page summarizes high-leverage tuning options.</p>"},{"location":"configuration/tuning/#what-to-do-first-highest-impact","title":"What to do first (highest impact)","text":""},{"location":"configuration/tuning/#1-improve-context-and-knowledge","title":"1. Improve context and knowledge","text":"<ul> <li>Fill in real gotchas. The scaffold <code>knowledge/gotchas.md</code> is mostly placeholders. Replace them with concrete caveats (freshness, delays, segment definitions, historical gaps). The agent uses these to warn users and avoid wrong interpretations.</li> <li>Add domain and glossary. Use <code>knowledge/business.md</code> for glossary terms, business model, and how metrics are interpreted in your company. This reduces ambiguity and wrong metric choice.</li> <li>Use semantic metadata. In <code>semantic_models.yaml</code>, add <code>synonyms</code> and <code>description</code> (and metric/dimension gotchas) so the agent maps natural language to the right metrics and dimensions.</li> </ul> <p>Better grounding in your config and knowledge files often improves correctness more than upgrading the model.</p>"},{"location":"configuration/tuning/#2-adjust-scope-and-policy-if-you-want-broader-answers","title":"2. Adjust scope and policy (if you want broader answers)","text":"<p>The built-in system prompt is intentionally data-only: it tells the agent to answer from knowledge in the prompt or from tools, and to respond \"This request is outside my capabilities\" for anything else (e.g. code, emails, general advice).</p> <ul> <li>If you want the bot to be more generally helpful, you\u2019ll need to relax or change that policy (e.g. via <code>RULES.md</code> or future prompt extension points). Today the strict scope is by design to keep behavior predictable for data workloads.</li> <li>If you stay data-only, keep the default; it reduces drift and off-topic answers.</li> </ul>"},{"location":"configuration/tuning/#3-add-a-small-eval-harness","title":"3. Add a small eval harness","text":"<ul> <li>Add 30\u201350 real questions (ambiguous phrasing, entity resolution, date ranges, cases where gotchas apply) under <code>evals/</code>.</li> <li>Track: correct metric/dimension choice, correct filters, and whether answers are useful and mention caveats when relevant.</li> <li>Use this to compare prompt changes and model choices instead of relying on ad-hoc testing.</li> </ul>"},{"location":"configuration/tuning/#4-model-and-routing","title":"4. Model and routing","text":"<ul> <li>Better model: Upgrading the model (e.g. to a larger or newer one) can help, but gains are often incremental compared to fixing context and evals.</li> <li>Routing: Use a fast/cheap default model and escalate to a stronger model only when confidence is low, tools fail, or the question is complex. This improves both quality and cost.</li> </ul>"},{"location":"configuration/tuning/#5-timeouts-query-took-too-long","title":"5. Timeouts (\"query took too long\")","text":"<ul> <li>Model vs query vs Slack: <code>advanced.model_timeout_seconds</code> limits how long the LLM has to respond (single turn). <code>advanced.query_timeout_seconds</code> limits each tool call (e.g. warehouse query). <code>advanced.slack_run_timeout_seconds</code> is the outer timeout for a whole Slack run (model + tools). If you see \"query took too long,\" check which layer is slow: raise <code>model_timeout_seconds</code> for slow/reasoning models, <code>query_timeout_seconds</code> for heavy or slow warehouse queries, or <code>slack_run_timeout_seconds</code> if the whole Slack request needs more time.</li> </ul>"},{"location":"configuration/tuning/#6-tool-loops","title":"6. Tool loops","text":"<ul> <li>If the agent seems to \\\"get stuck\\\" repeatedly calling tools instead of answering, lower <code>advanced.tool_calls_limit</code> and/or <code>advanced.request_limit</code>. The system prompt also instructs the model to answer once it has data from <code>query_metric</code> instead of re-querying.\\n*** End Patch```}\"/&gt;</li> </ul>"},{"location":"configuration/tuning/#order-of-operations","title":"Order of operations","text":"<p>A practical order:</p> <ol> <li>Fix policy and context (gotchas, business knowledge, synonyms).</li> <li>Add evals and iterate on prompts and knowledge using them.</li> <li>Then tune model choice (and routing if you add it).</li> </ol>"},{"location":"configuration/tuning/#related-docs","title":"Related docs","text":"<ul> <li>Context engineering \u2014 where to put context (RULES, knowledge, semantic_models).</li> <li>Agent configuration \u2014 <code>falk_project.yaml</code> and related files.</li> <li>Evals \u2014 how to define and run evaluation cases.</li> </ul>"},{"location":"deployment/logfire/","title":"Logfire Observability","text":"<p>Logfire provides tracing, cost tracking, and feedback for your data agent.</p>"},{"location":"deployment/logfire/#what-logfire-adds","title":"What Logfire Adds","text":"Feature Without Logfire With Logfire Feedback Logged (not persisted) Structured feedback with scores Observability None Full traces (LLM calls, tools) Cost tracking None Token usage and API costs per query"},{"location":"deployment/logfire/#setup","title":"Setup","text":""},{"location":"deployment/logfire/#1-authenticate","title":"1. Authenticate","text":"<pre><code>logfire auth\n</code></pre>"},{"location":"deployment/logfire/#2-create-a-project","title":"2. Create a project","text":"<pre><code>logfire projects new\n</code></pre>"},{"location":"deployment/logfire/#3-configure-environment","title":"3. Configure environment","text":"<p>Add to your <code>.env</code> file:</p> <pre><code>LOGFIRE_TOKEN=...\n</code></pre> <p>(Or <code>LOGTAIL_TOKEN</code> for legacy compatibility.)</p> <p>That's it. The agent will automatically trace runs when Logfire is configured.</p>"},{"location":"deployment/logfire/#what-gets-traced","title":"What Gets Traced","text":"<p>Every agent interaction creates a trace in Logfire with:</p> <ul> <li>User query \u2014 The original question</li> <li>Agent response \u2014 The final answer</li> <li>Tool calls \u2014 Each tool invocation (query_metric, export, etc.)</li> <li>Model info \u2014 Which LLM was used, token usage, cost</li> <li>Metadata \u2014 User ID, channel, thread (for Slack)</li> </ul>"},{"location":"deployment/logfire/#feedback-collection","title":"Feedback Collection","text":"<p>When users react with thumbs up/down in Slack:</p> <ul> <li>Positive (\ud83d\udc4d) \u2014 Score of <code>1.0</code> recorded in Logfire</li> <li>Negative (\ud83d\udc4e) \u2014 Score of <code>0.0</code> recorded in Logfire</li> </ul> <p>Feedback is linked to the trace via <code>trace_id</code>.</p>"},{"location":"deployment/logfire/#fallback-behavior","title":"Fallback Behavior","text":"<p>If Logfire is not configured (LOGFIRE_TOKEN not set):</p> <ul> <li>Agent works normally</li> <li>Feedback is logged to console but not persisted</li> <li>No traces or cost tracking</li> </ul>"},{"location":"deployment/logfire/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/logfire/#logfire-env-vars-set-but-package-not-installed","title":"\"Logfire env vars set but package not installed\"","text":"<pre><code>uv sync\n</code></pre>"},{"location":"deployment/logfire/#no-traces-appearing","title":"No traces appearing","text":"<ul> <li>Run <code>logfire auth</code> and <code>logfire projects new</code></li> <li>Verify LOGFIRE_TOKEN is in <code>.env</code></li> <li>Check agent logs for Logfire warnings</li> </ul>"},{"location":"deployment/slack/","title":"Slack Bot","text":"<p>The primary way teams interact with falk in production.</p>"},{"location":"deployment/slack/#setup","title":"Setup","text":""},{"location":"deployment/slack/#1-create-a-slack-app","title":"1. Create a Slack app","text":"<p>Go to api.slack.com/apps \u2192 Create New App \u2192 From scratch.</p>"},{"location":"deployment/slack/#2-enable-socket-mode","title":"2. Enable Socket Mode","text":"<p>Settings \u2192 Socket Mode \u2192 toggle ON \u2192 create an App-Level Token with <code>connections:write</code> scope.</p> <p>Copy the <code>xapp-...</code> token \u2192 <code>SLACK_APP_TOKEN</code>.</p>"},{"location":"deployment/slack/#3-create-slash-command","title":"3. Create slash command","text":"<p>Features \u2192 Slash Commands \u2192 Create New Command:</p> Field Value Command <code>/falk</code> Request URL <code>https://fredehagelund92.github.io</code> (Socket Mode uses websocket; URL not called) Short Description Query your data"},{"location":"deployment/slack/#4-subscribe-to-events","title":"4. Subscribe to events","text":"<p>Features \u2192 Event Subscriptions \u2192 toggle ON \u2192 add bot events:</p> Event Why <code>app_mention</code> Respond when @mentioned in channels <code>message.im</code> Respond to direct messages <code>reaction_added</code> Track \ud83d\udc4d/\ud83d\udc4e feedback"},{"location":"deployment/slack/#5-set-bot-token-scopes","title":"5. Set bot token scopes","text":"<p>Features \u2192 OAuth &amp; Permissions \u2192 add:</p> <ul> <li><code>app_mentions:read</code></li> <li><code>chat:write</code></li> <li><code>commands</code> \u2014 for /falk slash command</li> <li><code>files:write</code> \u2014 upload CSV, Excel, chart files</li> <li><code>im:history</code></li> <li><code>im:read</code></li> <li><code>reactions:read</code></li> </ul> <p>Install the app and copy the Bot Token \u2192 <code>SLACK_BOT_TOKEN</code>.</p>"},{"location":"deployment/slack/#6-configure-env","title":"6. Configure <code>.env</code>","text":"<pre><code>SLACK_BOT_TOKEN=xoxb-...   # OAuth &amp; Permissions \u2192 Bot User OAuth Token\nSLACK_APP_TOKEN=xapp-...   # Basic Information \u2192 App-Level Tokens\n</code></pre>"},{"location":"deployment/slack/#7-run","title":"7. Run","text":"<pre><code>falk slack\n</code></pre>"},{"location":"deployment/slack/#features","title":"Features","text":"<ul> <li>Slash command \u2014 <code>/falk What is our revenue?</code> works without @mentioning the bot</li> <li>Thread memory \u2014 follow-up questions in the same thread preserve context</li> <li>File uploads \u2014 CSV, Excel, and chart files are uploaded directly to the channel</li> <li>Feedback \u2014 \ud83d\udc4d/\ud83d\udc4e reactions are sent to LangFuse as scores</li> </ul>"},{"location":"deployment/slack/#how-feedback-works","title":"How feedback works","text":"<p>When users react to the bot's messages:</p> Reaction What happens \ud83d\udc4d Positive score sent to LangFuse (if configured) \ud83d\udc4e Negative score sent to LangFuse (if configured) <p>Data stewards review feedback in the Logfire dashboard, add corrections, and update config files. See Logfire Observability.</p>"},{"location":"deployment/web-ui/","title":"Web UI","text":"<p>Local web chat for testing, powered by Pydantic AI's built-in web interface.</p>"},{"location":"deployment/web-ui/#run","title":"Run","text":"<pre><code>falk chat\n</code></pre> <p>Starts the app at:</p> <ul> <li><code>http://127.0.0.1:8000</code></li> </ul> <p>No separate frontend is required.</p>"},{"location":"deployment/web-ui/#when-to-use","title":"When to use","text":"<ul> <li>Local development \u2014 test queries before deploying to Slack</li> <li>Debugging \u2014 validate prompt/tool behavior in a browser flow</li> <li>Demos \u2014 show the agent to stakeholders quickly</li> </ul>"},{"location":"deployment/web-ui/#backend-api-optional","title":"Backend API (optional)","text":"<p>Start the web app directly if needed:</p> <pre><code>uv run uvicorn app.web:app --reload\n</code></pre> <p>This starts the FastAPI app at <code>http://127.0.0.1:8000</code>. The <code>falk chat</code> command uses this same app.</p> <p>Note: All logic lives in the <code>falk</code> library \u2014 the same code powers the CLI chat, Slack bot, and MCP server.</p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>PostgreSQL for session storage (Falk creates schema and tables automatically)</li> <li>API key for OpenAI, Anthropic Claude, or Google Gemini</li> <li>(Recommended) uv for fast package management</li> </ul>"},{"location":"getting-started/installation/#install-from-source","title":"Install from Source","text":"<pre><code># Clone the repository\ngit clone https://github.com/Fredehagelund92/Falk.git\ncd falk\n\n# Set up virtual environment\nuv venv &amp;&amp; uv sync\n\n# Or with pip\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\npip install -e .\n</code></pre>"},{"location":"getting-started/installation/#install-from-pypi","title":"Install from PyPI","text":"<pre><code>pip install falk\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<pre><code># Check CLI is available\nfalk --help\n\n# Create a project\nfalk init my-project\ncd my-project\n\n# Configure environment\ncp .env.example .env\n# Edit .env: set POSTGRES_URL and your LLM API key (e.g. OPENAI_API_KEY)\n\n# Validate\nfalk validate --fast\n\n# Query through one of the interfaces\nfalk chat\n# or\nfalk mcp\n</code></pre>"},{"location":"getting-started/installation/#configure-llm-provider","title":"Configure LLM Provider","text":"<p>falk supports multiple LLM providers via Pydantic AI. Set your preferred provider in <code>.env</code>:</p> <pre><code># OpenAI (default)\nOPENAI_API_KEY=sk-...\n\n# Anthropic Claude\nANTHROPIC_API_KEY=sk-ant-...\n\n# Google Gemini\nGOOGLE_API_KEY=...\n</code></pre> <p>See LLM Provider Configuration for details.</p>"},{"location":"getting-started/installation/#optional-logfire-observability","title":"Optional: Logfire Observability","text":"<p>For production monitoring, add Logfire Cloud:</p> <pre><code># .env\nLOGFIRE_TOKEN=...\n</code></pre> <p>Run <code>logfire auth</code> and <code>logfire projects new</code> first. All queries, LLM calls, and user feedback will be traced automatically.</p>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#falk-command-not-found","title":"\"falk: command not found\"","text":"<p>Ensure the virtual environment is activated:</p> <pre><code>source .venv/bin/activate  # macOS/Linux\n.venv\\Scripts\\activate     # Windows\npip install -e .\n</code></pre>"},{"location":"getting-started/installation/#no-metrics-found","title":"\"No metrics found\"","text":"<p>Check that:</p> <ol> <li><code>semantic_models.yaml</code> exists and is valid YAML</li> <li>The database path in <code>.env</code> is correct</li> <li>Table names in <code>semantic_models.yaml</code> match your database</li> </ol>"},{"location":"getting-started/installation/#api-key-error","title":"\"API key error\"","text":"<p>Verify your API key is set in <code>.env</code> and is valid.</p>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start \u2014 Build your first project</li> <li>Semantic Models \u2014 Define your metrics</li> <li>CLI Reference \u2014 All available commands</li> </ul>"},{"location":"getting-started/mcp/","title":"Using falk with MCP Clients","text":"<p>falk exposes its governed metric queries through the Model Context Protocol (MCP), allowing any MCP client to query your data warehouse safely.</p>"},{"location":"getting-started/mcp/#what-is-mcp","title":"What is MCP?","text":"<p>The Model Context Protocol is a standardized way for AI applications to connect to external tools and services. falk uses FastMCP, a higher-level MCP framework from the Pydantic AI ecosystem that provides a simpler, more Pythonic API.</p> <p>With falk's MCP server, you can:</p> <ul> <li>Query falk from Cursor while coding</li> <li>Ask falk questions in Claude Desktop</li> <li>Build custom agents that use falk's MCP server as a data tool</li> <li>Chain falk with other MCP servers for complex workflows</li> </ul>"},{"location":"getting-started/mcp/#starting-the-mcp-server","title":"Starting the MCP Server","text":"<pre><code># Start the MCP server\nfalk mcp\n</code></pre> <p>The MCP server will: 1. Load your project configuration from <code>falk_project.yaml</code> 2. Connect to your semantic models 3. Expose tools for querying metrics</p>"},{"location":"getting-started/mcp/#available-mcp-tools","title":"Available MCP Tools","text":"<p>falk exposes these tools via MCP:</p>"},{"location":"getting-started/mcp/#discovery-metadata","title":"Discovery &amp; Metadata","text":"<ul> <li><code>list_catalog(entity_type)</code> \u2014 List metrics and/or dimensions (entity_type: metric | dimension | both)</li> <li><code>suggest_date_range(period)</code> \u2014 Get common date ranges (last_7_days, this_month, etc.)</li> <li><code>describe_metric</code> \u2014 Get full description of a metric</li> <li><code>describe_model</code> \u2014 Get full description of a semantic model</li> <li><code>describe_dimension</code> \u2014 Get full description of a dimension</li> <li><code>lookup_dimension_values</code> \u2014 Look up actual values for a dimension</li> <li><code>disambiguate(entity_type, concept)</code> \u2014 Find close metric/dimension matches for clarification</li> </ul>"},{"location":"getting-started/mcp/#querying","title":"Querying","text":"<ul> <li><code>query_metric</code> \u2014 Query metrics with optional grouping, filtering, compare_period, include_share</li> </ul>"},{"location":"getting-started/mcp/#tool-name-mapping-agent-vs-mcp","title":"Tool Name Mapping (Agent vs MCP)","text":"<ul> <li>Agent tool name: <code>lookup_values</code></li> <li>MCP tool name: <code>lookup_dimension_values</code></li> <li>These are equivalent capabilities exposed through different interfaces.</li> </ul>"},{"location":"getting-started/mcp/#connecting-from-cursor","title":"Connecting from Cursor","text":"<ol> <li> <p>Start the MCP server: <pre><code>falk mcp\n</code></pre></p> </li> <li> <p>Configure Cursor to connect to falk:</p> </li> </ol> <p>Open Cursor settings and add falk as an MCP server:    <pre><code>{\n  \"mcpServers\": {\n    \"falk\": {\n      \"command\": \"falk\",\n      \"args\": [\"mcp\"],\n      \"cwd\": \"/path/to/your/falk-project\"\n    }\n  }\n}\n</code></pre></p> <ol> <li>Query naturally in Cursor: <pre><code>You: \"Show me revenue by region\"\n\u2192 Cursor calls falk's query_metric tool\n\nYou: \"Compare revenue this month vs last\"\n\u2192 Cursor calls falk's query_metric with compare_period=\"month\"\n</code></pre></li> </ol>"},{"location":"getting-started/mcp/#connecting-from-claude-desktop","title":"Connecting from Claude Desktop","text":"<ol> <li> <p>Configure Claude Desktop in <code>claude_desktop_config.json</code>:    <pre><code>{\n  \"mcpServers\": {\n    \"falk\": {\n      \"command\": \"falk\",\n      \"args\": [\"mcp\"],\n      \"cwd\": \"/path/to/your/falk-project\"\n    }\n  }\n}\n</code></pre></p> </li> <li> <p>Restart Claude Desktop to load the new MCP server</p> </li> <li> <p>Ask questions in Claude Desktop:</p> </li> <li>\"List available metrics\"</li> <li>\"Show revenue trends by product\"</li> <li>\"Why did sales drop last quarter?\"</li> </ol>"},{"location":"getting-started/mcp/#using-from-other-agents","title":"Using from Other Agents","text":"<p>If you're building your own Pydantic AI agent, you can connect to falk's MCP server using FastMCP:</p> <pre><code>from pydantic_ai import Agent\nfrom pydantic_ai.toolsets.fastmcp import FastMCPToolset\n\n# Create toolset from falk MCP server\nfalk_toolset = FastMCPToolset({\n    'mcpServers': {\n        'falk': {\n            'command': 'falk',\n            'args': ['mcp'],\n            'cwd': '/path/to/your/falk-project'\n        }\n    }\n})\n\n# Create agent with falk toolset\nagent = Agent('openai:gpt-4', toolsets=[falk_toolset])\n\n# Now your agent can use falk's tools\nresult = await agent.run(\"What's our revenue by region?\")\nprint(result.output)\n</code></pre>"},{"location":"getting-started/mcp/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Cursor / IDE   \u2502\u2500\u2500\u2500\u2500\u2510\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n                       \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Claude Desktop  \u2502\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25b6\u2502  falk MCP    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502   Server     \u2502\n                       \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502           \u2502\n\u2502  Custom Agent   \u2502\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n                                   \u25bc\n                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                          \u2502   DataAgent     \u2502\n                          \u2502 (Semantic Layer)\u2502\n                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u25bc\n                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                          \u2502   Warehouse     \u2502\n                          \u2502 (DuckDB/SF/BQ)  \u2502\n                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"getting-started/mcp/#tool-examples","title":"Tool Examples","text":""},{"location":"getting-started/mcp/#query-a-metric","title":"Query a metric","text":"<pre><code># MCP client calls:\nquery_metric(\n    metrics=[\"revenue\"],\n    dimensions=[\"region\"],\n    time_grain=\"month\",\n    limit=10\n)\n\n# Returns:\n{\n    \"rows\": [\n        {\"region\": \"US\", \"revenue\": 100000},\n        {\"region\": \"EU\", \"revenue\": 85000},\n        ...\n    ],\n    \"row_count\": 10,\n    \"metrics\": [\"revenue\"],\n    \"model\": \"sales_metrics\"\n}\n</code></pre>"},{"location":"getting-started/mcp/#query-with-filters","title":"Query with filters","text":"<p>Use structured filters:</p> <pre><code># Simple equality\nquery_metric(\n    metrics=[\"revenue\"],\n    dimensions=[\"product_category\"],\n    filters=[{\"field\": \"region\", \"op\": \"=\", \"value\": \"US\"}],\n)\n\n# Comparisons\nquery_metric(\n    metrics=[\"revenue\"],\n    dimensions=[\"region\"],\n    filters=[{\"field\": \"date\", \"op\": \"&gt;=\", \"value\": \"2024-01-01\"}],\n)\n\n# Multiple conditions with AND\nquery_metric(\n    metrics=[\"revenue\"],\n    dimensions=[\"product_category\"],\n    filters=[\n        {\"field\": \"region\", \"op\": \"=\", \"value\": \"US\"},\n        {\"field\": \"date\", \"op\": \"&gt;=\", \"value\": \"2024-01-01\"},\n    ],\n)\n\n# IN clause for multiple values\nquery_metric(\n    metrics=[\"revenue\"],\n    dimensions=[\"product_category\"],\n    filters=[{\"field\": \"region\", \"op\": \"IN\", \"value\": [\"US\", \"EU\", \"APAC\"]}],\n)\n</code></pre>"},{"location":"getting-started/mcp/#compare-periods","title":"Compare periods","text":"<p>Use <code>query_metric</code> with <code>compare_period=\"week\"|\"month\"|\"quarter\"</code> to compare a metric across current vs previous period.</p>"},{"location":"getting-started/mcp/#benefits-of-mcp","title":"Benefits of MCP","text":"<ol> <li>Standardized interface \u2014 Same tools work in Cursor, Claude, custom agents</li> <li>Governed access \u2014 All queries go through your semantic layer</li> <li>Composable \u2014 Chain falk with other MCP servers</li> <li>Secure \u2014 MCP server runs locally with your credentials</li> <li>Type-safe \u2014 Tool schemas ensure valid requests</li> </ol>"},{"location":"getting-started/mcp/#next-steps","title":"Next Steps","text":"<ul> <li>MCP Configuration \u2014 Advanced MCP server settings</li> <li>Tool Reference \u2014 Complete list of MCP tools</li> <li>CLI Chat \u2014 Interactive terminal interface</li> <li>Slack Bot \u2014 Team collaboration interface</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get a working falk project in under 5 minutes.</p>"},{"location":"getting-started/quickstart/#1-install","title":"1. Install","text":"<pre><code>git clone https://github.com/Fredehagelund92/Falk.git\ncd falk\nuv venv &amp;&amp; uv sync\n</code></pre>"},{"location":"getting-started/quickstart/#2-create-a-project","title":"2. Create a project","text":"<pre><code>falk init my-analytics\ncd my-analytics\n</code></pre> <p>This creates:</p> <pre><code>my-analytics/\n\u251c\u2500\u2500 RULES.md                    # Agent behavior rules\n\u251c\u2500\u2500 knowledge/                  # Business context + known caveats\n\u2502   \u251c\u2500\u2500 business.md\n\u2502   \u2514\u2500\u2500 gotchas.md\n\u251c\u2500\u2500 evals/                      # Starter eval cases\n\u2502   \u251c\u2500\u2500 basic.yaml\n\u2502   \u251c\u2500\u2500 access.yaml\n\u2502   \u2514\u2500\u2500 gotchas.yaml\n\u251c\u2500\u2500 semantic_models.yaml       # Metrics &amp; dimensions\n\u251c\u2500\u2500 falk_project.yaml          # Agent config\n\u251c\u2500\u2500 data/\n\u2502   \u2514\u2500\u2500 warehouse.duckdb       # Sample data (90 days)\n\u2514\u2500\u2500 .env.example\n</code></pre>"},{"location":"getting-started/quickstart/#3-add-your-api-key","title":"3. Add your API key","text":"<pre><code>cp .env.example .env\n# Edit .env: OPENAI_API_KEY=sk-...\n</code></pre>"},{"location":"getting-started/quickstart/#4-verify","title":"4. Verify","text":"<pre><code>falk validate --fast\n</code></pre> <pre><code>\u2705 Configuration valid!\n  \u2713 Semantic models: 1 model, 6 metrics, 4 dimensions\n</code></pre>"},{"location":"getting-started/quickstart/#5-start-querying","title":"5. Start querying","text":"<pre><code># Option 1: Web UI\nfalk chat\n# \u2192 http://localhost:8000\n\n# Option 2: MCP server (connect from Cursor / Claude Desktop)\nfalk mcp\n</code></pre> <p>Try asking:</p> <ul> <li>\"What's our total revenue?\"</li> <li>\"Top 5 regions by revenue\"</li> <li>\"Compare revenue this month vs last\"</li> </ul>"},{"location":"getting-started/quickstart/#6-make-it-yours","title":"6. Make it yours","text":""},{"location":"getting-started/quickstart/#define-your-metrics","title":"Define your metrics","text":"<p>Edit <code>semantic_models.yaml</code>:</p> <pre><code>my_model:\n  table: my_table\n  database: [my_schema]\n  description: \"What this model represents\"\n  dimensions:\n    date:\n      expr: _.date\n      is_time_dimension: true\n    region:\n      expr: _.region\n      description: \"Sales region\"\n      synonyms: [\"territory\", \"area\"]\n  measures:\n    revenue:\n      expr: _.revenue.sum()\n      description: \"Total revenue (completed orders)\"\n      synonyms: [\"sales\", \"income\"]\n      related_metrics: [orders, average_order_value]\n</code></pre>"},{"location":"getting-started/quickstart/#add-business-context","title":"Add business context","text":"<p>Edit <code>RULES.md</code> and fill in <code>knowledge/</code> files with your domain knowledge. See Context Engineering.</p>"},{"location":"getting-started/quickstart/#deploy-to-slack","title":"Deploy to Slack","text":"<pre><code># Add Slack tokens to .env\nfalk slack\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next steps","text":"<ul> <li>Semantic Models \u2014 full configuration reference</li> <li>Context Engineering \u2014 teach the agent about your business</li> <li>CLI Reference \u2014 all commands</li> <li>Slack Bot \u2014 deploy for your team</li> </ul>"},{"location":"reference/where-syntax/","title":"WHERE Clause Syntax","text":"<p>falk's MCP <code>query_metric</code> tool supports SQL-like WHERE clauses for filtering query results.</p>"},{"location":"reference/where-syntax/#supported-syntax","title":"Supported Syntax","text":""},{"location":"reference/where-syntax/#equality","title":"Equality","text":"<pre><code>region = 'US'\ncustomer_segment = 'Enterprise'\n</code></pre> <p>Converts to: <code>{\"region\": \"US\"}</code></p>"},{"location":"reference/where-syntax/#comparisons","title":"Comparisons","text":"<pre><code>date &gt;= '2024-01-01'\nrevenue &gt; 100000\ndate &lt;= '2024-12-31'\n</code></pre> <p>Converts to: - <code>{\"date\": {\"gte\": \"2024-01-01\"}}</code> - <code>{\"revenue\": {\"gt\": 100000}}</code> - <code>{\"date\": {\"lte\": \"2024-12-31\"}}</code></p>"},{"location":"reference/where-syntax/#multiple-conditions-and","title":"Multiple Conditions (AND)","text":"<pre><code>region = 'US' AND date &gt;= '2024-01-01'\nregion = 'US' AND date &gt;= '2024-01-01' AND date &lt;= '2024-12-31'\n</code></pre> <p>Converts to: - <code>{\"region\": \"US\", \"date\": {\"gte\": \"2024-01-01\"}}</code> - <code>{\"region\": \"US\", \"date\": {\"gte\": \"2024-01-01\", \"lte\": \"2024-12-31\"}}</code></p>"},{"location":"reference/where-syntax/#in-clause","title":"IN Clause","text":"<pre><code>region IN ('US', 'EU', 'APAC')\ncustomer_segment IN ('Enterprise', 'SMB')\n</code></pre> <p>Converts to: - <code>{\"region\": [\"US\", \"EU\", \"APAC\"]}</code> - <code>{\"customer_segment\": [\"Enterprise\", \"SMB\"]}</code></p>"},{"location":"reference/where-syntax/#supported-operators","title":"Supported Operators","text":"Operator BSL Format Example <code>=</code> Direct value <code>region = 'US'</code> <code>&gt;</code> <code>{\"gt\": value}</code> <code>revenue &gt; 1000</code> <code>&gt;=</code> <code>{\"gte\": value}</code> <code>date &gt;= '2024-01-01'</code> <code>&lt;</code> <code>{\"lt\": value}</code> <code>revenue &lt; 10000</code> <code>&lt;=</code> <code>{\"lte\": value}</code> <code>date &lt;= '2024-12-31'</code> <code>!=</code> <code>{\"ne\": value}</code> <code>status != 'cancelled'</code> <code>IN (...)</code> <code>[value1, value2]</code> <code>region IN ('US', 'EU')</code>"},{"location":"reference/where-syntax/#value-types","title":"Value Types","text":"<p>The parser automatically detects value types:</p>"},{"location":"reference/where-syntax/#strings","title":"Strings","text":"<p>Must be quoted with single or double quotes: <pre><code>region = 'US'\nregion = \"US\"  -- also works\n</code></pre></p>"},{"location":"reference/where-syntax/#numbers","title":"Numbers","text":"<p>No quotes needed: <pre><code>revenue &gt; 100000\nprice &lt;= 99.99\n</code></pre></p>"},{"location":"reference/where-syntax/#booleans","title":"Booleans","text":"<p>Use <code>true</code> or <code>false</code> (case-insensitive): <pre><code>is_active = true\nis_deleted = false\n</code></pre></p>"},{"location":"reference/where-syntax/#dates","title":"Dates","text":"<p>Quoted strings (auto-detected): <pre><code>date &gt;= '2024-01-01'\ncreated_at &lt;= '2024-12-31'\n</code></pre></p>"},{"location":"reference/where-syntax/#combining-filters-on-same-dimension","title":"Combining Filters on Same Dimension","text":"<p>Multiple conditions on the same dimension are merged:</p> <pre><code>date &gt;= '2024-01-01' AND date &lt;= '2024-12-31'\n</code></pre> <p>Converts to: <pre><code>{\"date\": {\"gte\": \"2024-01-01\", \"lte\": \"2024-12-31\"}}\n</code></pre></p> <p>This creates a date range filter (between Jan 1 and Dec 31, 2024).</p>"},{"location":"reference/where-syntax/#examples-from-mcp-clients","title":"Examples from MCP Clients","text":""},{"location":"reference/where-syntax/#cursor","title":"Cursor","text":"<pre><code>You: \"Show me revenue for US customers in 2024\"\n\n\u2192 Cursor calls:\nquery_metric(\n    metric=\"revenue\",\n    dimensions=[\"customer_segment\"],\n    where=\"region = 'US' AND date &gt;= '2024-01-01' AND date &lt;= '2024-12-31'\"\n)\n</code></pre>"},{"location":"reference/where-syntax/#claude-desktop","title":"Claude Desktop","text":"<pre><code>You: \"Compare Enterprise vs SMB revenue for Q1\"\n\n\u2192 Claude calls:\nquery_metric(\n    metric=\"revenue\",\n    dimensions=[\"customer_segment\"],\n    where=\"customer_segment IN ('Enterprise', 'SMB') AND date &gt;= '2024-01-01' AND date &lt;= '2024-03-31'\"\n)\n</code></pre>"},{"location":"reference/where-syntax/#limitations","title":"Limitations","text":""},{"location":"reference/where-syntax/#not-supported-yet","title":"NOT Supported Yet","text":"<ul> <li>OR conditions \u2014 Only AND is supported</li> <li>Nested conditions \u2014 No parentheses grouping</li> <li>LIKE patterns \u2014 No wildcards or pattern matching</li> <li>IS NULL / IS NOT NULL \u2014 No null checking</li> <li>Complex expressions \u2014 No calculated fields in WHERE</li> </ul>"},{"location":"reference/where-syntax/#workarounds","title":"Workarounds","text":"<p>For complex filters, use <code>lookup_dimension_values</code> first to find valid values, then query with simple conditions.</p>"},{"location":"reference/where-syntax/#how-it-works","title":"How It Works","text":"<p>Under the hood, the WHERE parser:</p> <ol> <li>Splits the string by <code>AND</code> keywords</li> <li>Parses each condition for operator and value</li> <li>Converts to BSL filter dict format</li> <li>Merges multiple conditions on the same dimension</li> </ol> <p>This makes MCP tool calls feel natural (SQL-like) while maintaining BSL's structured filter system for security and type safety.</p>"},{"location":"reference/where-syntax/#see-also","title":"See Also","text":"<ul> <li>MCP Tools Reference \u2014 All available tools</li> <li>Semantic Models \u2014 Define dimensions and metrics</li> <li>Query Examples \u2014 More query patterns</li> </ul>"}]}