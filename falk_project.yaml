# falk Configuration
# Single source for agent behavior, extensions, and access control.
# Metrics and dimensions are defined in semantic_models.yaml (Boring Semantic Layer)

version: 1

# Database Connection (inline ‚Äî no separate profiles file)
connection:
  type: duckdb
  database: data/warehouse.duckdb

# Agent Configuration (analyst-facing)
agent:
  # LLM Provider
  provider: openai  # openai, anthropic, gemini, mistral
  model: gpt-4o-mini  # or gpt-4o, claude-sonnet-4, gemini-pro, etc.
  
  # Business Context - This is your company's data story
  context: |
    We're a SaaS company selling analytics software.
    The funnel is: trials -> signups -> paid customers -> revenue.
    "Customer" = organization using our software.
  
  # Example Questions - Help users know what to ask
  examples:
    - "What's our revenue by region this month?"
    - "Show me top 5 customers by trials"
    - "Compare this week to last week"
    - "Daily breakdown of conversions"
  
  # Rules - Important constraints the agent should follow
  rules:
    - "Revenue data has a 24-hour processing delay"
    - "Always mention the date range when showing results"
    - "Use 'MRR' not 'monthly recurring revenue'"
  
  # Welcome Message
  welcome: |
    üëã Hi! I can help you explore your data.
    Try asking: "What's our revenue by region?" or "Show me top customers"

# Extensions - Pluggable integrations
extensions:
  # Observability & Tracing
  langfuse:
    enabled: false  # Set to true and add keys to .env to enable
    sync: true  # Flush after each trace (ensures data sent before process exit)
  
  # Slack Integration
  slack:
    enabled: false  # Enable when deploying to Slack
    feedback_reactions: true  # Collect üëç/üëé
    channels: []  # Empty = all channels, or specify: ["#data-questions"]
  
  # Chart Generation
  charts:
    enabled: true
    default_type: auto  # auto, bar, line, pie
    formats: [png, html]
    max_categories: 20
  
  # Exports
  exports:
    enabled: true
    formats: [csv, excel, google_sheets]
    max_rows: 100000
  
  # Future: dbt Integration
  dbt:
    enabled: false
    project_dir: null
    sync_on_startup: false

# Data Access Control
access:
  # access_policy: access_policy.yaml  # If set and file exists, row-level filtering enabled

# Agent Skills - Bring your own skills (pydantic-ai-skills)
# See https://github.com/DougTrajano/pydantic-ai-skills
skills:
  enabled: false  # Set to true to enable custom skills
  directories: ["./skills"]  # Directory(ies) containing SKILL.md files

# Paths (relative to project root)
paths:
  semantic_models: semantic_models.yaml  # BSL file

# Advanced Settings (technical)
advanced:
  auto_run: false
  max_tokens: 4096
  temperature: 0.1
  max_rows_per_query: 10000
  query_timeout_seconds: 30
  # Retry settings
  max_retries: 3
  retry_delay_seconds: 1
  
  # Logging
  log_level: INFO  # DEBUG, INFO, WARNING, ERROR

