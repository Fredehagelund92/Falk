# Learning & Feedback

The agent does not learn from conversations. It improves when humans update config files based on feedback and evals.

## Feedback loop

```
User asks question
     â†“
Agent answers â†’ trace in Logfire
     â†“
User reacts ğŸ‘ or ğŸ‘ â†’ score in Logfire
     â†“
Data steward reviews low scores
     â†“
Updates config/context files â†’ agent improves
```

## The improvement cycle

1. **Find issues** â€” filter Logfire traces by low scores
2. **Understand why** â€” see the full trace (query â†’ tools â†’ response)
3. **Fix the source** â€” update synonyms, gotchas, rules, or context
4. **Write a test** â€” add a case to `evals/` to prevent regression
5. **Verify** â€” `falk test`

## Everything is files

All agent knowledge lives in version-controlled files. No database. No migrations. PR-reviewed and version-controlled.

## See also

- [Context](/concepts/context) â€” where vocabulary, gotchas, and domain knowledge live
- [Memory](/concepts/memory) â€” what persists (knowledge vs session vs feedback)
